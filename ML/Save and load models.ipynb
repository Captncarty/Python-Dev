{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dee0041",
   "metadata": {},
   "source": [
    "<b>Model progress</b> can be saved during and after training. This means a model can resume where it _left off and avoid long training times_. Saving also means you can share your model and others can recreate your work. When publishing research models and techniques, most machine learning practitioners share:\n",
    "\n",
    "code to create the model, and\n",
    "\n",
    "the trained weights, or parameters, for the model\n",
    "\n",
    "Sharing this data helps others understand how the model works and try it themselves with new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308cd0b8",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Install and import TensorFlow and dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0975016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.9/site-packages (6.0)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.9/site-packages (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/anaconda3/lib/python3.9/site-packages (from h5py) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyyaml h5py  # Required to save models in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8700da13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f865c9",
   "metadata": {},
   "source": [
    "#### Get an example dataset\n",
    "\n",
    "To demonstrate how to save and load weights, you'll use the <u>MNIST dataset.</u> To speed up these runs, _use the first 1000 examples:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef12192",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0      # storing in a range from 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19783e3b",
   "metadata": {},
   "source": [
    "### Define a model\n",
    "\n",
    "Start by building a simple sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fc3024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c62e0f",
   "metadata": {},
   "source": [
    "#### Save checkpoints during training\n",
    "\n",
    "You can use a trained model without having to retrain it, or pick-up training where you left off in case the training process was interrupted. The <b>tf.keras.callbacks.ModelCheckpoint callback</b> allows you to continually save the model both during and at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9a1e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0300 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4095 - val_sparse_categorical_accuracy: 0.8620\n",
      "\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0231 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4133 - val_sparse_categorical_accuracy: 0.8750\n",
      "\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0213 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4102 - val_sparse_categorical_accuracy: 0.8720\n",
      "\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0180 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4234 - val_sparse_categorical_accuracy: 0.8720\n",
      "\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0141 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4093 - val_sparse_categorical_accuracy: 0.8790\n",
      "\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0122 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4245 - val_sparse_categorical_accuracy: 0.8700\n",
      "\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0106 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4185 - val_sparse_categorical_accuracy: 0.8710\n",
      "\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0099 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4351 - val_sparse_categorical_accuracy: 0.8680\n",
      "\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0090 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4385 - val_sparse_categorical_accuracy: 0.8690\n",
      "\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0088 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4380 - val_sparse_categorical_accuracy: 0.8690\n",
      "\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1595fe850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=10,\n",
    "          validation_data=(test_images, test_labels),\n",
    "          callbacks=[cp_callback])  # Pass callback to training\n",
    "\n",
    "# This may generate warnings related to saving the state of the optimizer.\n",
    "# These warnings (and similar warnings throughout this notebook)\n",
    "# are in place to discourage outdated usage, and can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b4d464",
   "metadata": {},
   "source": [
    "##### This creates a single collection of TensorFlow checkpoint files that are updated at the end of each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "307c965b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp.ckpt.data-00000-of-00001', 'checkpoint', 'cp.ckpt.index']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7452d06",
   "metadata": {},
   "source": [
    "As long as two models share the same <b>architecture</b> you can share _weights_ between them. So, when restoring a model from weights-only, <u>create a model with the same architecture as the original model and then set its weights.</u>\n",
    "\n",
    "Now rebuild a fresh, untrained model and evaluate it on the test set. An untrained model will perform at chance levels (~10% accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee0fe42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.3717 - sparse_categorical_accuracy: 0.0670\n",
      "Untrained model, accuracy:  6.70%\n"
     ]
    }
   ],
   "source": [
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c090bc9",
   "metadata": {},
   "source": [
    "#### Then load the weights from the checkpoint and re-evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95d865ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4380 - sparse_categorical_accuracy: 0.8690\n",
      "Restored model, accuracy: 86.90%\n"
     ]
    }
   ],
   "source": [
    "# Loads the weights\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ac762",
   "metadata": {},
   "source": [
    "#### Checkpoint callback options\n",
    "\n",
    "The callback provides several options to provide unique names for checkpoints and adjust the checkpointing frequency.\n",
    "\n",
    "Train a new model, and save uniquely named checkpoints once every five epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8762e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
      "\n",
      "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
      "\n",
      "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
      "\n",
      "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
      "\n",
      "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
      "\n",
      "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
      "\n",
      "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
      "\n",
      "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
      "\n",
      "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152928670>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=5*batch_size)\n",
    "\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "          train_labels,\n",
    "          epochs=50, \n",
    "          batch_size=batch_size, \n",
    "          callbacks=[cp_callback],\n",
    "          validation_data=(test_images, test_labels),\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea0d406",
   "metadata": {},
   "source": [
    "##### Now, look at the resulting checkpoints and choose the latest one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09397fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp-0005.ckpt.data-00000-of-00001',\n",
       " 'cp-0050.ckpt.index',\n",
       " 'cp-0005.ckpt.index',\n",
       " 'cp-0050.ckpt.data-00000-of-00001',\n",
       " 'checkpoint',\n",
       " 'cp-0020.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.index',\n",
       " 'cp-0030.ckpt.index',\n",
       " 'cp-0025.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.data-00000-of-00001',\n",
       " 'cp-0035.ckpt.index',\n",
       " 'cp-0010.ckpt.index',\n",
       " 'cp-0045.ckpt.index',\n",
       " 'cp-0045.ckpt.data-00000-of-00001',\n",
       " 'cp-0010.ckpt.data-00000-of-00001',\n",
       " 'cp-0035.ckpt.data-00000-of-00001',\n",
       " 'cp-0015.ckpt.index',\n",
       " 'cp-0040.ckpt.index',\n",
       " 'cp-0025.ckpt.index',\n",
       " 'cp-0030.ckpt.data-00000-of-00001',\n",
       " 'cp-0040.ckpt.data-00000-of-00001',\n",
       " 'cp-0015.ckpt.data-00000-of-00001',\n",
       " 'cp-0020.ckpt.index']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bd88f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2/cp-0050.ckpt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest\n",
    "\n",
    "#### Note: the default TensorFlow format only saves the 5 most recent checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145aa4eb",
   "metadata": {},
   "source": [
    "### To test, reset the model and load the latest checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6519ee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4829 - sparse_categorical_accuracy: 0.8760\n",
      "Restored model, accuracy: 87.60%\n"
     ]
    }
   ],
   "source": [
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Load the previously saved weights\n",
    "model.load_weights(latest)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3941100",
   "metadata": {},
   "source": [
    "#### What are these files?\n",
    "\n",
    "The above code stores the weights to a collection of <b>checkpoint-formatted</b> files that contain only the trained weights in a binary format. Checkpoints contain:\n",
    "\n",
    "_One or more shards that contain your model's weights._\n",
    "\n",
    "_An index file that indicates which weights are stored in which shard._\n",
    "\n",
    "_If you are training a model on a single machine, you'll have one shard with the suffix: .data-00000-of-00001_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bcdb4a",
   "metadata": {},
   "source": [
    "#### Manually save weights\n",
    "\n",
    "Manually saving weights with the <b>Model.save_weights method.</b> By default, tf.keras—and save_weights in particular—uses the TensorFlow checkpoint format with a <b>.ckpt extension</b> (saving in HDF5 with a .h5 extension is covered in the Save and serialize models guide):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08cd09d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4829 - sparse_categorical_accuracy: 0.8760\n",
      "Restored model, accuracy: 87.60%\n"
     ]
    }
   ],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Restore the weights\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd04c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
