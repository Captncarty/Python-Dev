{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wat = 'watson'\n",
    "print(wat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d78b88d",
   "metadata": {},
   "source": [
    "#  Hashing of Password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97eb42",
   "metadata": {},
   "source": [
    "FIRST import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e689bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb675a2",
   "metadata": {},
   "source": [
    "THEN import hashlib from library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a15be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff56c9d8",
   "metadata": {},
   "source": [
    "### _Generation_ _example_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ed2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate Salt at 32byte\n",
    "salt = os.urandom(32)   #Unique random string known only to the site for each password!\n",
    "\n",
    "# hashing password and key derivation funct using hmac, (utf-8, byte conversion)\n",
    "key = hashlib.pbkdf2_hmac('sha256', 'mypassword'.encode('utf-8'), salt, 100000)\n",
    "\n",
    "#store \"salt and key\" in a variable\n",
    "storage = salt + key\n",
    "\n",
    "# Getting the values back\n",
    "salt_from_storage = storage[:32]\n",
    "key_from_storage = storage[32:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c73a75",
   "metadata": {},
   "source": [
    "### Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a04616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4bd70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt = b'' # Get the salt you stored for this user\n",
    "key = b'' # Get this users key calculated\n",
    "\n",
    "password_to_check = 'password246' # Provided password by this user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887a1f9",
   "metadata": {},
   "source": [
    "_Using the exact same setup used in generating the key_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef5894f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screwed\n"
     ]
    }
   ],
   "source": [
    "new_key = hashlib.pbkdf2_hmac('sha256', password_to_check.encode('utf-8'), salt, 100000)   #stored in new Variable\n",
    "\n",
    "# iterate\n",
    "if new_key == key:\n",
    "    print('Password is a GO')\n",
    "else:\n",
    "    print('Screwed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2126881e",
   "metadata": {},
   "source": [
    "### JUST HATCHED and verification failed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb98f2",
   "metadata": {},
   "source": [
    "# Round2 _(hashing)_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9190c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of Username and password for a specific client\n",
    "\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "users = {}     # A simple demo storage\n",
    "\n",
    "# Add a user\n",
    "username = 'brentwood'\n",
    "password = 'oluwa1234'\n",
    "\n",
    "salt = os.urandom(32)    # A new salt for this user\n",
    "key = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, 100000)\n",
    "users[username] = {   # store the salt and key!\n",
    "    'salt': salt,\n",
    "    'key': key\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5961fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'W\\x88\\xa0\\x9c(\\x0cll,\\xce\\xc2O\\x91\\x16*\\x86=\\xf3\\x97)\\xa7y\\x7fq\\xdb*3Qh\\x80\\xd1\\xa4'\n",
      "b'J\\x94VF\\x92\\xed#[\\xcec\\x9ag\\xd8\\xd8\\x97\\x13\\xecJ\\x0fz\\xc9\\xe4\\x17\\x84\\x969bA\\x1b\\xb3\\xf0\\xfc'\n"
     ]
    }
   ],
   "source": [
    "print(key)\n",
    "print(salt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916843f7",
   "metadata": {},
   "source": [
    "### Verification attempt 1 (Wrong password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c647afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screwed\n"
     ]
    }
   ],
   "source": [
    "username = 'brentwood'\n",
    "password = 'oluwaburna'\n",
    "\n",
    "salt = users[username]['salt'] # Get the salt\n",
    "key = users[username]['key']   # Get correct key\n",
    "new_key = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, 100000)\n",
    "\n",
    "if new_key == key:\n",
    "    print('Password is a GO')\n",
    "else:\n",
    "    print('Screwed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc3f1532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'W\\x88\\xa0\\x9c(\\x0cll,\\xce\\xc2O\\x91\\x16*\\x86=\\xf3\\x97)\\xa7y\\x7fq\\xdb*3Qh\\x80\\xd1\\xa4'\n",
      "b'J\\x94VF\\x92\\xed#[\\xcec\\x9ag\\xd8\\xd8\\x97\\x13\\xecJ\\x0fz\\xc9\\xe4\\x17\\x84\\x969bA\\x1b\\xb3\\xf0\\xfc'\n"
     ]
    }
   ],
   "source": [
    "print(key)\n",
    "print(salt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a2de97",
   "metadata": {},
   "source": [
    "### Verification  attempt 2 (Correct password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1e4489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password is a GO\n"
     ]
    }
   ],
   "source": [
    "username = 'brentwood'\n",
    "password = 'oluwa1234'\n",
    "\n",
    "salt = users[username]['salt'] # Get the salt\n",
    "key = users[username]['key']   # Get correct key\n",
    "new_key = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, 100000)\n",
    "\n",
    "if new_key == key:\n",
    "    print('Password is a GO')\n",
    "else:\n",
    "    print('Screwed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fb594ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'W\\x88\\xa0\\x9c(\\x0cll,\\xce\\xc2O\\x91\\x16*\\x86=\\xf3\\x97)\\xa7y\\x7fq\\xdb*3Qh\\x80\\xd1\\xa4'\n",
      "b'J\\x94VF\\x92\\xed#[\\xcec\\x9ag\\xd8\\xd8\\x97\\x13\\xecJ\\x0fz\\xc9\\xe4\\x17\\x84\\x969bA\\x1b\\xb3\\xf0\\xfc'\n"
     ]
    }
   ],
   "source": [
    "print(key)\n",
    "print(salt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321e1e9",
   "metadata": {},
   "source": [
    "### Adding a different user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3176d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'derick'\n",
    "password = 'my$ecur3p@$$w0rd'\n",
    "key = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, 100000)\n",
    "users[username] = {   # store the salt and key in a \"Demo Storage\"\n",
    "    'salt': salt,\n",
    "    'key': key\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeeca1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x7f\\xc3\\x84\\xa3\\xf3\\xa3\\xbd\\x93\\x80\\x98\\x8c\\xee\\x15\\xe8\\xdfx\\x92v;M\\x1a\\xe8\\x89h\\x86\\xd8\\xae\\x1a\\xf7\\x12\\xc0\\xd8'\n",
      "b'J\\x94VF\\x92\\xed#[\\xcec\\x9ag\\xd8\\xd8\\x97\\x13\\xecJ\\x0fz\\xc9\\xe4\\x17\\x84\\x969bA\\x1b\\xb3\\xf0\\xfc'\n"
     ]
    }
   ],
   "source": [
    "print(key)\n",
    "print(salt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891799f2",
   "metadata": {},
   "source": [
    "### Checking the other users password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e608a139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talk to Admin\n"
     ]
    }
   ],
   "source": [
    "username = 'derick'\n",
    "password = 'myecur3p@$$w0rd'\n",
    "\n",
    "salt = users[username]['salt'] # Get the salt\n",
    "key = users[username]['key']   # Get correct key\n",
    "new_key = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, 100000)\n",
    "\n",
    "if new_key == key:\n",
    "    print('Welcome home')\n",
    "elif username == username:\n",
    "    print('Talk to Admin')\n",
    "else:\n",
    "    print('Screwed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a29b88",
   "metadata": {},
   "source": [
    "# Today's Work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2501963",
   "metadata": {},
   "source": [
    "## _Getting today's date and time_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e965d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do I want today's date and time ? (y/n): \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today's date and time:\n",
      "2022-10-13 10:33:01.477354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "while True:\n",
    "    print('Do I want today\\'s date and time ? (y/n): ')\n",
    "    check = input()\n",
    "    if check == 'n':          #Note to self, more functions on check????\n",
    "            break\n",
    "    else:\n",
    "        print('today\\'s date and time:')\n",
    "        print(datetime.datetime.today())\n",
    "        print()\n",
    "        \n",
    "        break\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14057189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.today())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36001f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'bag'\n",
    "a = 'bat'\n",
    "print('a is not the same as b, (y/n):')\n",
    "check = input()  #To open a command / checking box\n",
    "if check == n:\n",
    "        break\n",
    "else:\n",
    "    print('unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243abc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wanna know the Date? (y/n): \n",
      "y\n",
      "today's date and time:\n",
      "2022-03-21 15:48:33.833377\n",
      "Wanna know the Date? (y/n): \n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "while True:\n",
    "    print('Wanna know the Date? (y/n): ')\n",
    "    check = input()\n",
    "    if check == 'n':\n",
    "            break\n",
    "    else:\n",
    "        print('today\\'s date and time:')\n",
    "        print(datetime.datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc50abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8548dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "547fae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.9/site-packages (2.6.3)\n",
      "Requirement already satisfied: clang~=5.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions<3.11,>=3.7 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c65cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 22:27:14.268840: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 2ms/step - loss: 0.2973 - accuracy: 0.9127\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1434 - accuracy: 0.9572\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1087 - accuracy: 0.9672: 0s - l\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0874 - accuracy: 0.9734\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9766\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0702 - accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07018651813268661, 0.9801999926567078]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eabd91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank1_tensor = tf.Variable(['Test', 'Ok', 'Tim'],['job', 'hub', 'tub'], tf.string)\n",
    "rank2_tensor = tf.Variable(['Test', 'Ok', 'Tim'], tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0396058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(rank1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e341d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57da58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e27ef",
   "metadata": {},
   "source": [
    "#### Load and prepare the MNIST dataset. Convert the sample data from integers to floating-point numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eef18e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b878aa9",
   "metadata": {},
   "source": [
    "# Build a machine learning model\n",
    "#### Build a tf.keras.Sequential model by stacking layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2095789",
   "metadata": {},
   "source": [
    "Importance and significant role of keras to Machine Learning??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "613e1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e2f920a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18852004,  0.45759806, -1.3295637 , -0.13844027, -0.0849997 ,\n",
       "        -0.02065983,  0.3253296 , -0.20067705,  0.10981667, -0.71511286]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions            # converts each model to logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec663a",
   "metadata": {},
   "source": [
    "#### The tf.nn.softmax function converts these logits to probabilities for each class:\n",
    "An array is faster python list and numpy can sort through arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d85d1497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12539865, 0.1641164 , 0.02747878, 0.09042652, 0.09539042,\n",
       "        0.10172957, 0.14378333, 0.08497021, 0.11590774, 0.05079841]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()    # makes it more intepretable "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ce584",
   "metadata": {},
   "source": [
    "Define a loss function for training using losses.SparseCategoricalCrossentropy, \n",
    "which takes a vector of logits and a True index and returns a scalar loss for each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2361bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "947aed1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.285437"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b14bc",
   "metadata": {},
   "source": [
    "##### This loss is equal to the negative log probability of the true class: The loss is zero if the model is sure of the correct class.\n",
    "_This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf.math.log(1/10) ~= 2.3._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c13bdc",
   "metadata": {},
   "source": [
    "##### Before you start training, configure and compile the model using Keras Model.compile. Set the optimizer class to adam, set the loss to the loss_fn function you defined earlier, and specify a metric to be evaluated for the model by setting the metrics parameter to accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9a67f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])    # Configuring the ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39fe7dc",
   "metadata": {},
   "source": [
    "### Train and evaluate your model\n",
    "Use the Model.fit method to adjust your model parameters and minimize the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5ba61d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0651 - accuracy: 0.9799\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0578 - accuracy: 0.9822\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0521 - accuracy: 0.9832\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0482 - accuracy: 0.9843\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0433 - accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10f205070>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5) # Adjust the above parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc9c2f0",
   "metadata": {},
   "source": [
    "### Checkn Model's performance\n",
    "Use the \"Model.evaluate\" method checks the models performance, usually on a \"Validation-set\" or \"Test-set\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a89e0892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0702 - accuracy: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07024403661489487, 0.980400025844574]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)    #??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab889e49",
   "metadata": {},
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7552a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd5020",
   "metadata": {},
   "source": [
    "#### Attempting to return back to probability\n",
    "If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c8cf846",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7102f1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9999, 10), dtype=float32, numpy=\n",
       "array([[1.85731031e-11, 2.60233377e-13, 6.86530566e-09, ...,\n",
       "        9.99998212e-01, 5.60720970e-10, 1.22928672e-08],\n",
       "       [1.38505852e-12, 5.19823402e-08, 1.00000000e+00, ...,\n",
       "        1.37424349e-19, 1.00260564e-10, 1.46508615e-19],\n",
       "       [4.53051152e-09, 9.99681473e-01, 8.01318129e-06, ...,\n",
       "        2.92996119e-04, 1.23933642e-05, 8.31174702e-08],\n",
       "       ...,\n",
       "       [2.61775107e-12, 7.31274552e-09, 1.53886003e-06, ...,\n",
       "        8.21895468e-11, 2.32208267e-10, 2.28065596e-06],\n",
       "       [3.17230949e-14, 2.38091534e-12, 5.28964325e-15, ...,\n",
       "        1.91844174e-06, 4.83425744e-08, 4.91593200e-05],\n",
       "       [1.91450696e-12, 9.54869647e-13, 1.38215253e-14, ...,\n",
       "        5.23149883e-12, 8.84852398e-06, 5.32821599e-11]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f47716",
   "metadata": {},
   "source": [
    "#### Congratulations! You have trained a machine learning model using a prebuilt dataset using the Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e361706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e767a6",
   "metadata": {},
   "source": [
    "## Keras    \n",
    "Keras is an open-source software library that provides a Python interface for artificial neural networks\n",
    "### Sequential model        â‡ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da33aabf",
   "metadata": {},
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f01b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d809d6c",
   "metadata": {},
   "source": [
    "### Creating a sequenciial model\n",
    "\n",
    "You can create a Sequential model by passing a list of layers to the Sequential constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1291bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\"),\n",
    "        layers.Dense(3, activation=\"relu\"),\n",
    "        layers.Dense(4),\n",
    "    ]\n",
    ")          # Its layers are accessible via the layers attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1133d147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x10f7bafa0>,\n",
       " <keras.layers.core.Dense at 0x10f4db550>,\n",
       " <keras.layers.core.Dense at 0x10f4d2070>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed50b6",
   "metadata": {},
   "source": [
    "##### You can also create a Sequential model incrementally via the add() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac344aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
